{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data handling\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paf/miniconda3/lib/python3.6/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/home/paf/miniconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Data preparation\n",
    "from sklearn.model_selection import train_test_split\n",
    "#\n",
    "from sklearn.utils import class_weight\n",
    "#\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/paf/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "#Old REPD model\n",
    "from REPD_Impl import REPD\n",
    "from autoencoder import AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Keras model support\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Performance metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Result presentation\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Visualization\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Other\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_arff(dataset_name, data_preparation_function):\n",
    "    #Load data\n",
    "    data, _ = arff.loadarff(\"./data/\"+dataset+\".arff\")\n",
    "    \n",
    "     # Wrap data into a pandas dataframe\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    #Prepare data\n",
    "    df = data_preparation_function(df)\n",
    "    \n",
    "    #Return dataframe\n",
    "    return df\n",
    "\n",
    "def load_csv(dataset_name, data_preparation_function):\n",
    "    #Load data\n",
    "    data = pd.read_csv(\"./data/\"+dataset_name+\".csv\")\n",
    "    \n",
    "    #Prepare data\n",
    "    df = data_preparation_function(data)\n",
    "    \n",
    "    #Return dataframe\n",
    "    return df\n",
    "\n",
    "def load_data(dataset_name, dataset_settings):\n",
    "    if dataset_settings[\"type\"] == \"arff\":\n",
    "        return load_arff(dataset_name, dataset_settings[\"prep_func\"])\n",
    "    elif dataset_settings[\"type\"] == \"csv\":\n",
    "        return load_csv(dataset_name, dataset_settings[\"prep_func\"])\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_defect_0_1_prep_func(defect_column_name, mapping_function):\n",
    "    #\n",
    "    def defect_0_1_prep_func(df):\n",
    "        df[defect_column_name] = df[defect_column_name].map(mapping_function)\n",
    "        return df\n",
    "    #\n",
    "    return defect_0_1_prep_func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cleanup_prep_func_decorator(prep_func):\n",
    "    #\n",
    "    def decorated_prep_func_1(df):\n",
    "        df = prep_func(df)\n",
    "        \n",
    "        #Remove all with missing values\n",
    "        df = df.dropna()\n",
    "\n",
    "        #Remove duplicate instances\n",
    "        df = df.drop_duplicates()\n",
    "        #\n",
    "        return df\n",
    "    #\n",
    "    return decorated_prep_func_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_adjust_defect_column_name_prep_func_decorator(defecive_column_name, prep_func):\n",
    "    #\n",
    "    def decorated_prep_func_2(df):\n",
    "        df = prep_func(df)\n",
    "        \n",
    "        #Rename column\n",
    "        df = df.rename(columns={defecive_column_name: \"defective\"})\n",
    "        #\n",
    "        return df\n",
    "    #\n",
    "    return decorated_prep_func_2        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_remove_column_prep_func_decorator(columns_to_remove, prep_func):\n",
    "    def decorated_prep_func_3(df):\n",
    "        df = prep_func(df)\n",
    "        \n",
    "        #Drop columns\n",
    "        df = df.drop(columns=columns_to_remove)\n",
    "        #\n",
    "        return df\n",
    "    #\n",
    "    return decorated_prep_func_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class REPD_EX:\n",
    "    \n",
    "    def __init__(self, base_repd, defective_classification_model, non_defective_classification_model, use_def_m=True, use_non_def_m=True):\n",
    "        self.base_repd = base_repd\n",
    "        self.defective_classification_model = defective_classification_model\n",
    "        self.non_defective_classification_model = non_defective_classification_model\n",
    "        self.use_def_m=use_def_m\n",
    "        self.use_non_def_m=use_non_def_m\n",
    "    \n",
    "    def fit(self, X, y, train_base=True):\n",
    "        #\n",
    "        if train_base:\n",
    "            X_m1_fit, X_m2_fit, y_m1_fit, y_m2_fit = train_test_split(X, y, test_size=0.5)\n",
    "            #\n",
    "            oversample = SMOTE()\n",
    "            X_m1_fit, y_m1_fit = oversample.fit_resample(X_m1_fit, y_m1_fit)\n",
    "            #\n",
    "            self.base_repd.fit(X_m1_fit,y_m1_fit)\n",
    "        else:\n",
    "            X_m2_fit = X\n",
    "            y_m2_fit = y\n",
    "        #\n",
    "        y_p = self.base_repd.predict(X_m2_fit)\n",
    "        X_r = pd.DataFrame(self.base_repd.transform(X_m2_fit))\n",
    "        #\n",
    "        #========================================\n",
    "        if self.use_def_m:\n",
    "            X_s_o_t = X_m2_fit[y_p==1]\n",
    "            X_s_r_t = X_r[y_p==1]\n",
    "            #\n",
    "            X_s_o_t = pd.DataFrame(X_s_o_t.values)\n",
    "            X_s_r_t = pd.DataFrame(X_s_r_t.values)\n",
    "            #\n",
    "            X_s_t = pd.concat([X_s_o_t, X_s_r_t], axis=1, join=\"inner\")\n",
    "            #\n",
    "            y_s_t = y_m2_fit[y_p==1]\n",
    "            #\n",
    "            #print(\"P Defective:\",len(y_s_t[y_s_t==1]),\"/\",len(y_s_t))\n",
    "            #\n",
    "            oversample = SMOTE()\n",
    "            X_s_t, y_s_t = oversample.fit_resample(X_s_t, y_s_t)\n",
    "            #\n",
    "            self.defective_classification_model.fit(X_s_t, y_s_t)\n",
    "        #========================================\n",
    "        if self.use_non_def_m:\n",
    "            X_s_o_t = X_m2_fit[y_p==0]\n",
    "            X_s_r_t = X_r[y_p==0]\n",
    "            #\n",
    "            X_s_o_t = pd.DataFrame(X_s_o_t.values)\n",
    "            X_s_r_t = pd.DataFrame(X_s_r_t.values)\n",
    "            #\n",
    "            X_s_t = pd.concat([X_s_o_t, X_s_r_t], axis=1, join=\"inner\")\n",
    "            #\n",
    "            y_s_t = y_m2_fit[y_p==0]\n",
    "            #\n",
    "            #print(\"P Defective:\",len(y_s_t[y_s_t==1]),\"/\",len(y_s_t))\n",
    "            #\n",
    "            oversample = SMOTE()\n",
    "            X_s_t, y_s_t = oversample.fit_resample(X_s_t, y_s_t)\n",
    "            #\n",
    "            self.non_defective_classification_model.fit(X_s_t, y_s_t)\n",
    "        #========================================\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_p = self.base_repd.predict(X)\n",
    "        #\n",
    "        X_r = pd.DataFrame(self.base_repd.transform(X))\n",
    "        #\n",
    "        #========================================\n",
    "        if self.use_def_m:\n",
    "            X_s_o_t = X[y_p==1]\n",
    "            X_s_r_t = X_r[y_p==1]\n",
    "            #\n",
    "            X_s_o_t = pd.DataFrame(X_s_o_t.values)\n",
    "            X_s_r_t = pd.DataFrame(X_s_r_t.values)\n",
    "            #\n",
    "            X_s_t = pd.concat([X_s_o_t, X_s_r_t], axis=1, join=\"inner\")\n",
    "            #\n",
    "            y_s_p_p = self.defective_classification_model.predict(X_s_t)\n",
    "        #========================================\n",
    "        if self.use_non_def_m:\n",
    "            X_s_o_t = X[y_p==0]\n",
    "            X_s_r_t = X_r[y_p==0]\n",
    "            #\n",
    "            X_s_o_t = pd.DataFrame(X_s_o_t.values)\n",
    "            X_s_r_t = pd.DataFrame(X_s_r_t.values)\n",
    "            #\n",
    "            X_s_t = pd.concat([X_s_o_t, X_s_r_t], axis=1, join=\"inner\")\n",
    "            #\n",
    "            y_s_n_p = self.non_defective_classification_model.predict(X_s_t)\n",
    "        #========================================\n",
    "        r = []\n",
    "        #\n",
    "        cnt1 = 0\n",
    "        k1 = 0\n",
    "        cnt2 = 0\n",
    "        k2 = 0\n",
    "        for v in y_p:\n",
    "            if v == 0:\n",
    "                if self.use_non_def_m:\n",
    "                    if hasattr(y_s_n_p[k2], \"__len__\"):\n",
    "                        nmr = y_s_n_p[k2][0]\n",
    "                    else:\n",
    "                        nmr = y_s_n_p[k2]\n",
    "                    if nmr >= 0.5:\n",
    "                        r.append(1)\n",
    "                    else:\n",
    "                        r.append(0)\n",
    "                        cnt2 = cnt2 + 1\n",
    "                    k2 = k2 + 1\n",
    "                else:\n",
    "                    r.append(0)\n",
    "            else:\n",
    "                if self.use_def_m:\n",
    "                    if hasattr(y_s_p_p[k1], \"__len__\"):\n",
    "                        nmr = y_s_p_p[k1][0]\n",
    "                    else:\n",
    "                        nmr = y_s_p_p[k1]\n",
    "                    if nmr >= 0.5:\n",
    "                        r.append(1)\n",
    "                        cnt1 = cnt1 + 1\n",
    "                    else:\n",
    "                        r.append(0)\n",
    "                    k1 = k1 + 1\n",
    "                else:\n",
    "                    r.append(1)\n",
    "        #\n",
    "        #print(\"S:\", len(X), \"P:\", len(y_s_p_p), \"C1:\", cnt1, \"N:\", len(y_s_n_p), \"C2:\", cnt2)\n",
    "        #\n",
    "        return y_p, np.asarray(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate performance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_results(y_true,y_predicted):\n",
    "    accuracy = accuracy_score(y_true, y_predicted)\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_predicted, average='binary')\n",
    "    return accuracy, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_res(column):\n",
    "    bp_dict = results_df.boxplot(\n",
    "        column=column,\n",
    "        by=[\"Model\"],\n",
    "        layout=(1,1),       \n",
    "        return_type='both',\n",
    "        patch_artist = True,\n",
    "        vert=False,\n",
    "    )    \n",
    "    plt.suptitle(\"\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    \"JDT_R2_0\",\"JDT_R2_1\",\"JDT_R3_0\",\"JDT_R3_1\",\"JDT_R3_2\",\n",
    "    \"PDE_R2_0\",\"PDE_R2_1\",\"PDE_R3_0\",\"PDE_R3_1\",\"PDE_R3_2\"\n",
    "]\n",
    "dataset_settings = {\n",
    "  \"JDT_R2_0\": {\n",
    "      \"type\":\"csv\",\n",
    "      \"prep_func\": get_cleanup_prep_func_decorator(\n",
    "                      get_remove_column_prep_func_decorator( [\"File\"],\n",
    "                      get_adjust_defect_column_name_prep_func_decorator(\"bug_cnt\",\n",
    "                          get_defect_0_1_prep_func(\"bug_cnt\", lambda x: 1 if x>0 else 0)\n",
    "                    ))\n",
    "                  )\n",
    "  },\n",
    "  \"JDT_R2_1\": {\n",
    "      \"type\":\"csv\",\n",
    "      \"prep_func\": get_cleanup_prep_func_decorator(\n",
    "                      get_remove_column_prep_func_decorator( [\"File\"],\n",
    "                      get_adjust_defect_column_name_prep_func_decorator(\"bug_cnt\",\n",
    "                          get_defect_0_1_prep_func(\"bug_cnt\", lambda x: 1 if x>0 else 0)\n",
    "                    ))\n",
    "                  )      \n",
    "  },\n",
    "  \"JDT_R3_0\": {\n",
    "      \"type\":\"csv\",\n",
    "      \"prep_func\": get_cleanup_prep_func_decorator(\n",
    "                      get_remove_column_prep_func_decorator( [\"File\"],\n",
    "                          get_adjust_defect_column_name_prep_func_decorator(\"bug_cnt\",\n",
    "                              get_defect_0_1_prep_func(\"bug_cnt\", lambda x: 1 if x>0 else 0)\n",
    "                      )\n",
    "                    )\n",
    "                  )      \n",
    "  },\n",
    "  \"JDT_R3_1\": {\n",
    "      \"type\":\"csv\",\n",
    "      \"prep_func\": get_cleanup_prep_func_decorator(\n",
    "                      get_remove_column_prep_func_decorator( [\"File\"],\n",
    "                          get_adjust_defect_column_name_prep_func_decorator(\"bug_cnt\",\n",
    "                              get_defect_0_1_prep_func(\"bug_cnt\", lambda x: 1 if x>0 else 0)\n",
    "                      )\n",
    "                    )\n",
    "                  )\n",
    "      \n",
    "  },\n",
    "  \"JDT_R3_2\": {\n",
    "      \"type\":\"csv\",\n",
    "      \"prep_func\": get_cleanup_prep_func_decorator(\n",
    "                      get_remove_column_prep_func_decorator( [\"File\"],\n",
    "                          get_adjust_defect_column_name_prep_func_decorator(\"bug_cnt\",\n",
    "                              get_defect_0_1_prep_func(\"bug_cnt\", lambda x: 1 if x>0 else 0)\n",
    "                        )\n",
    "                    )\n",
    "                  )      \n",
    "  },\n",
    "  \"PDE_R2_0\": {\n",
    "      \"type\":\"csv\",\n",
    "      \"prep_func\": get_cleanup_prep_func_decorator(\n",
    "                      get_remove_column_prep_func_decorator( [\"File\"],\n",
    "                      get_adjust_defect_column_name_prep_func_decorator(\"bug_cnt\",\n",
    "                          get_defect_0_1_prep_func(\"bug_cnt\", lambda x: 1 if x>0 else 0)\n",
    "                    ))\n",
    "                  )\n",
    "  },\n",
    "  \"PDE_R2_1\": {\n",
    "      \"type\":\"csv\",\n",
    "      \"prep_func\": get_cleanup_prep_func_decorator(\n",
    "                      get_remove_column_prep_func_decorator( [\"File\"],\n",
    "                      get_adjust_defect_column_name_prep_func_decorator(\"bug_cnt\",\n",
    "                          get_defect_0_1_prep_func(\"bug_cnt\", lambda x: 1 if x>0 else 0)\n",
    "                    ))\n",
    "                  )      \n",
    "  },\n",
    "  \"PDE_R3_0\": {\n",
    "      \"type\":\"csv\",\n",
    "      \"prep_func\": get_cleanup_prep_func_decorator(\n",
    "                      get_remove_column_prep_func_decorator( [\"File\"],\n",
    "                          get_adjust_defect_column_name_prep_func_decorator(\"bug_cnt\",\n",
    "                              get_defect_0_1_prep_func(\"bug_cnt\", lambda x: 1 if x>0 else 0)\n",
    "                      )\n",
    "                    )\n",
    "                  )      \n",
    "  },\n",
    "  \"PDE_R3_1\": {\n",
    "      \"type\":\"csv\",\n",
    "      \"prep_func\": get_cleanup_prep_func_decorator(\n",
    "                      get_remove_column_prep_func_decorator( [\"File\"],\n",
    "                          get_adjust_defect_column_name_prep_func_decorator(\"bug_cnt\",\n",
    "                              get_defect_0_1_prep_func(\"bug_cnt\", lambda x: 1 if x>0 else 0)\n",
    "                      )\n",
    "                    )\n",
    "                  )\n",
    "      \n",
    "  },\n",
    "  \"PDE_R3_2\": {\n",
    "      \"type\":\"csv\",\n",
    "      \"prep_func\": get_cleanup_prep_func_decorator(\n",
    "                      get_remove_column_prep_func_decorator( [\"File\"],\n",
    "                          get_adjust_defect_column_name_prep_func_decorator(\"bug_cnt\",\n",
    "                              get_defect_0_1_prep_func(\"bug_cnt\", lambda x: 1 if x>0 else 0)\n",
    "                        )\n",
    "                    )\n",
    "                  )      \n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_data = {\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset:  JDT_R2_0\n",
      "Defective: 1069 / 2265 = 0.47196467991169977\n",
      "\n",
      "Loading dataset:  JDT_R2_1\n",
      "Defective: 868 / 2591 = 0.3350057892705519\n",
      "\n",
      "Loading dataset:  JDT_R3_0\n",
      "Defective: 1310 / 3254 = 0.4025814382298709\n",
      "\n",
      "Loading dataset:  JDT_R3_1\n",
      "Defective: 1258 / 3727 = 0.3375368929433861\n",
      "\n",
      "Loading dataset:  JDT_R3_2\n",
      "Defective: 814 / 2117 = 0.38450637694851203\n",
      "\n",
      "Loading dataset:  PDE_R2_0\n",
      "Defective: 111 / 564 = 0.19680851063829788\n",
      "\n",
      "Loading dataset:  PDE_R2_1\n",
      "Defective: 124 / 739 = 0.16779431664411368\n",
      "\n",
      "Loading dataset:  PDE_R3_0\n",
      "Defective: 272 / 857 = 0.31738623103850644\n",
      "\n",
      "Loading dataset:  PDE_R3_1\n",
      "Defective: 355 / 1059 = 0.3352219074598678\n",
      "\n",
      "Loading dataset:  PDE_R3_2\n",
      "Defective: 620 / 1304 = 0.4754601226993865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print(\"Loading dataset: \", dataset)\n",
    "    df = load_data(dataset,dataset_settings[dataset])\n",
    "    #\n",
    "    dataset_data[dataset] = {\n",
    "        \"df\": df,\n",
    "        \"X\": df.drop(columns=[\"defective\"]),\n",
    "        \"y\": df[\"defective\"],\n",
    "        \"share\": (len(df[df[\"defective\"]==1])/ len(df))\n",
    "    }\n",
    "    #\n",
    "    print(\"Defective:\", len(df[df[\"defective\"]==1]), \"/\", len(df),\"=\",(len(df[df[\"defective\"]==1])/ len(df)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPETITION_COUNT = 100\n",
    "TEST_SIZE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for dataset in dataset_data:\n",
    "    dataset_data[dataset][\"train\"] = []\n",
    "    dataset_data[dataset][\"test\"] = []\n",
    "    # \n",
    "    X = dataset_data[dataset][\"X\"]\n",
    "    y = dataset_data[dataset][\"y\"]\n",
    "    #\n",
    "    for _ in range(REPETITION_COUNT):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE)\n",
    "        #\n",
    "        train_min = X_train.min()\n",
    "        train_dim = X_train.max() - X_train.min()\n",
    "        train_dim[train_dim == 0] = 1\n",
    "        #\n",
    "        X_train = (X_train - train_min) / train_dim\n",
    "        X_test = (X_test - train_min) / train_dim\n",
    "        #\n",
    "        X_train = X_train.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "        X_test = X_test.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "        #\n",
    "        dataset_data[dataset][\"train\"].append((X_train, y_train))\n",
    "        dataset_data[dataset][\"test\"].append((X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating for: JDT_R2_0  Mode: hr Share: 0.47196467991169977\n",
      "Repetition:  10\n",
      "Mean:           F1 score  Precision    Recall\n",
      "Model                                  \n",
      "OLD_REPD  0.611834   0.615948  0.609449\n",
      "REPD_EX   0.674549   0.560362  0.849734\n",
      "Median:           F1 score  Precision    Recall\n",
      "Model                                  \n",
      "OLD_REPD  0.600311   0.613815  0.587079\n",
      "REPD_EX   0.669241   0.553978  0.843733\n",
      "\n",
      "\n",
      "Calculating for: JDT_R2_1  Mode: hr Share: 0.3350057892705519\n",
      "Repetition:  10\n",
      "Mean:           F1 score  Precision    Recall\n",
      "Model                                  \n",
      "OLD_REPD  0.574891   0.502241  0.678264\n",
      "REPD_EX   0.604381   0.453100  0.910564\n",
      "Median:           F1 score  Precision    Recall\n",
      "Model                                  \n",
      "OLD_REPD  0.574841   0.499863  0.670175\n",
      "REPD_EX   0.608377   0.460586  0.910813\n",
      "\n",
      "\n",
      "Calculating for: JDT_R3_0  Mode: hr Share: 0.4025814382298709\n",
      "Repetition:  10\n",
      "Mean:           F1 score  Precision    Recall\n",
      "Model                                  \n",
      "OLD_REPD  0.651050   0.613440  0.697799\n",
      "REPD_EX   0.643532   0.507253  0.882928\n",
      "Median:           F1 score  Precision    Recall\n",
      "Model                                  \n",
      "OLD_REPD  0.655293   0.610348  0.714756\n",
      "REPD_EX   0.648491   0.514149  0.881550\n",
      "\n",
      "\n",
      "Calculating for: JDT_R3_1  Mode: hr Share: 0.3375368929433861\n",
      "Repetition:  10\n",
      "Mean:           F1 score  Precision    Recall\n",
      "Model                                  \n",
      "OLD_REPD  0.572741   0.514799  0.649714\n",
      "REPD_EX   0.575622   0.433753  0.858508\n",
      "Median:           F1 score  Precision    Recall\n",
      "Model                                  \n",
      "OLD_REPD  0.570849   0.516165  0.658120\n",
      "REPD_EX   0.581598   0.442845  0.870462\n",
      "\n",
      "\n",
      "Calculating for: JDT_R3_2  Mode: hr Share: 0.38450637694851203\n",
      "Repetition:  10\n",
      "Mean:           F1 score  Precision    Recall\n",
      "Model                                  \n",
      "OLD_REPD  0.619635   0.607805  0.635903\n",
      "REPD_EX   0.627077   0.491699  0.866801\n",
      "Median:           F1 score  Precision    Recall\n",
      "Model                                  \n",
      "OLD_REPD  0.623507   0.605438  0.635552\n",
      "REPD_EX   0.631016   0.491609  0.869632\n",
      "\n",
      "\n",
      "Calculating for: PDE_R2_0  Mode: hr Share: 0.19680851063829788\n",
      "Repetition:  10\n",
      "Mean:           F1 score  Precision    Recall\n",
      "Model                                  \n",
      "OLD_REPD  0.475072    0.34652  0.781219\n",
      "REPD_EX   0.475160    0.32006  0.950317\n",
      "Median:           F1 score  Precision    Recall\n",
      "Model                                  \n",
      "OLD_REPD  0.478537   0.354167  0.788889\n",
      "REPD_EX   0.476842   0.318609  1.000000\n",
      "\n",
      "\n",
      "Calculating for: PDE_R2_1  Mode: hr Share: 0.16779431664411368\n",
      "Repetition:  10\n",
      "Mean:           F1 score  Precision    Recall\n",
      "Model                                  \n",
      "OLD_REPD  0.365240   0.279416  0.557800\n",
      "REPD_EX   0.426957   0.291080  0.834278\n",
      "Median:           F1 score  Precision    Recall\n",
      "Model                                  \n",
      "OLD_REPD  0.366029   0.271264  0.554945\n",
      "REPD_EX   0.421833   0.280357  0.851648\n",
      "\n",
      "\n",
      "Calculating for: PDE_R3_0  Mode: hr Share: 0.31738623103850644\n",
      "Repetition:  10\n",
      "Mean:           F1 score  Precision    Recall\n",
      "Model                                  \n",
      "OLD_REPD   0.52692   0.450756  0.657066\n",
      "REPD_EX    0.53261   0.382208  0.885875\n",
      "Median:           F1 score  Precision  Recall\n",
      "Model                                \n",
      "OLD_REPD  0.490346   0.433508  0.6250\n",
      "REPD_EX   0.513429   0.359126  0.8775\n",
      "\n",
      "\n",
      "Calculating for: PDE_R3_1  Mode: hr Share: 0.3352219074598678\n",
      "Repetition:  10\n",
      "Mean:           F1 score  Precision    Recall\n",
      "Model                                  \n",
      "OLD_REPD  0.582253   0.489125  0.726090\n",
      "REPD_EX   0.572161   0.417834  0.910119\n",
      "Median:           F1 score  Precision    Recall\n",
      "Model                                  \n",
      "OLD_REPD  0.584969   0.485565  0.714214\n",
      "REPD_EX   0.559596   0.409427  0.910428\n",
      "\n",
      "\n",
      "Calculating for: PDE_R3_2  Mode: hr Share: 0.4754601226993865\n",
      "Repetition:  10\n",
      "Mean:           F1 score  Precision    Recall\n",
      "Model                                  \n",
      "OLD_REPD  0.504376   0.564102  0.461733\n",
      "REPD_EX   0.602744   0.510408  0.738504\n",
      "Median:           F1 score  Precision    Recall\n",
      "Model                                  \n",
      "OLD_REPD  0.492979   0.558824  0.446860\n",
      "REPD_EX   0.611667   0.524515  0.754032\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for mode, cls_w_c1, cls_w_c2, use_c1, use_c2 in [\n",
    "                                #(\"balance\",{0:1., 1: 2.},{0:2., 1: 1.},True, True), \n",
    "                                #(\"hp\",{0:2, 1: 1.},{0:1., 1: 1.},True,False),\n",
    "                                (\"hr\",{0:1., 1: 1.},{0:1., 1: 1.},False,True)\n",
    "                                ]:\n",
    "    for dataset in dataset_data:\n",
    "        print(\"Calculating for:\", dataset, \" Mode:\", mode, \"Share:\",dataset_data[dataset][\"share\"])\n",
    "        #\n",
    "        performance_data = []\n",
    "        #\n",
    "        for i in range(REPETITION_COUNT):\n",
    "            if (i+1)%10 ==0:\n",
    "                print(\"Repetition: \", (i+1))\n",
    "            #\n",
    "            try:\n",
    "                #\n",
    "                X_train, y_train = dataset_data[dataset][\"train\"][i]\n",
    "                X_test, y_test = dataset_data[dataset][\"test\"][i]\n",
    "                #\n",
    "                X_m1_fit, X_m2_fit, y_m1_fit, y_m2_fit = train_test_split(X_train, y_train, test_size=0.8)\n",
    "                #\n",
    "                #==================================================================\n",
    "                #OLD REPD\n",
    "                #print(\"OLD_REPD\")\n",
    "                autoencoder = AutoEncoder([48,24],0.01,100,50)\n",
    "                classifer = REPD(autoencoder)\n",
    "                classifer.fit(X_m1_fit, y_m1_fit)\n",
    "                y_p = classifer.predict(X_test)\n",
    "                accuracy, precision, recall, f1_score = calculate_results(y_test, y_p)\n",
    "\n",
    "                #Store results\n",
    "                data = ['OLD_REPD', accuracy, precision, recall, f1_score, accuracy, precision, recall, f1_score]\n",
    "                performance_data.append(data)\n",
    "\n",
    "                #REPD_EX\n",
    "                #print(\"REPD_EX\")\n",
    "                #\n",
    "                #class_weight = {0:1., 1: 2.} # #1 -> better F1 in combination with #2\n",
    "                #class_weight = {0:2, 1: 1.} #->do 100% precizno s 20% recall\n",
    "                final_classifier_1 = LogisticRegression(class_weight=cls_w_c1)\n",
    "                                    #VotingClassifier(estimators=[\n",
    "                                    #    ('rf', DecisionTreeClassifier(class_weight=class_weight)), \n",
    "                                    #    ('lr', LogisticRegression(class_weight=class_weight)), \n",
    "                                    #    ('gnb', GaussianNB()),\n",
    "                                    #    ('svm', SVC(class_weight=class_weight)),\n",
    "                                    #    ('boost',GradientBoostingClassifier())\n",
    "                                    #])\n",
    "                #\n",
    "                #class_weight = {0:1., 1: 1.2}\n",
    "                #class_weight = {0:2., 1: 1.} # #2 -> better F1 in combination with #1\n",
    "                final_classifier_2 =  LogisticRegression(class_weight=cls_w_c2)\n",
    "                                    #VotingClassifier(estimators=[\n",
    "                                    #    ('rf', DecisionTreeClassifier(class_weight=class_weight)), \n",
    "                                    #    ('lr', LogisticRegression(class_weight=class_weight)), \n",
    "                                    #    ('gnb', GaussianNB()),\n",
    "                                    #    ('svm', SVC(class_weight=class_weight)),\n",
    "                                    #    ('boost',GradientBoostingClassifier())\n",
    "                                    #])\n",
    "                #\n",
    "                classifer = REPD_EX(base_repd=classifer, \n",
    "                                    defective_classification_model=final_classifier_1,\n",
    "                                    non_defective_classification_model=final_classifier_2,\n",
    "                                    use_def_m=use_c1,#True\n",
    "                                    use_non_def_m=use_c2)#True\n",
    "                classifer.fit(X_m2_fit, y_m2_fit, train_base=False)\n",
    "                #\n",
    "                #print(\"Test defective share: \", len(y_test[y_test==1]), \"/\", len(y_test))\n",
    "                #\n",
    "                y_pb, y_p = classifer.predict(X_test)\n",
    "                accuracy_base, precision_base, recall_base, f1_base_score = calculate_results(y_test, y_pb)\n",
    "                accuracy, precision, recall, f1_score = calculate_results(y_test, y_p)\n",
    "\n",
    "                #Store results\n",
    "                data = ['REPD_EX', accuracy, precision, recall, f1_score, accuracy_base, precision_base, recall_base, f1_base_score]\n",
    "                performance_data.append(data)\n",
    "\n",
    "                #Close\n",
    "                autoencoder.close()    \n",
    "                #==================================================================\n",
    "                #oversample = SMOTE()\n",
    "                #X_smote, y_smote = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "                #classifer = DecisionTreeClassifier()\n",
    "                #classifer.fit(X_smote, y_smote)\n",
    "                #y_p = classifer.predict(X_test)\n",
    "                #accuracy, precision, recall, f1_score = calculate_results(y_test, y_p)\n",
    "\n",
    "                #Store results\n",
    "                #data = ['DecisionTree', accuracy, precision, recall, f1_score, accuracy, precision, recall, f1_score]\n",
    "                #performance_data.append(data)\n",
    "                #==================================================================\n",
    "\n",
    "                #\n",
    "                #print()\n",
    "            except Exception as e:\n",
    "                print(\"ERROR:\", e)\n",
    "                traceback.print_exc(file=sys.stdout)\n",
    "        #\n",
    "        results_df = pd.DataFrame(performance_data, columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 score', 'Accuracy base', 'Precision base', 'Recall base', 'F1 base score'])\n",
    "        results_df.to_csv(\"results/\"+mode+\"_\"+dataset)\n",
    "        #\n",
    "        #print()\n",
    "        print(\"Mean:\", results_df.groupby([\"Model\"])[\"F1 score\", 'Precision', 'Recall'].mean())\n",
    "        #print()\n",
    "        print(\"Median:\", results_df.groupby([\"Model\"])[\"F1 score\", 'Precision', 'Recall'].median())    \n",
    "        print()\n",
    "        print()\n",
    "        #repd_ex = results_df[results_df[\"Model\"]==\"REPD_EX\"]\n",
    "        #max_p = repd_ex[\"Precision\"].max()\n",
    "        #best = repd_ex[repd_ex[\"Precision\"]==max_p]\n",
    "        #print(best[[\"F1 score\",\"Precision\",\"Recall\"]])\n",
    "        #print(best[[\"F1 base score\",\"Precision base\",\"Recall base\"]])    \n",
    "        #print()\n",
    "        #\n",
    "        #plot_res(\"F1 score\")\n",
    "        #plot_res(\"Recall\")\n",
    "        #plot_res(\"Precision\")    \n",
    "        #\n",
    "        #print()\n",
    "        #print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
